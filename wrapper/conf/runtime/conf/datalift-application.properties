# Datalift application configuration
#
# Set the "datalift.home" Java VM system property (or the "DATALIFT_HOME"
# environment variable to point at the root directory of the Datalift
# installation
#
# ============================================================================
#
# Local installation paths
#
# The directory where to look for Datalift modules
datalift.modules.path           = \
        ${datalift.root}/modules,${datalift.home}/modules
#
# The private and public file system storage paths
datalift.private.storage.path   = ${datalift.home}/storage
datalift.public.storage.path    = ${datalift.private.storage.path}/public
#
# ============================================================================
#
# The RDF repositories
#
# Two repository names are recognized and reserved:
#  - data:      the public (i.e. published) RDF data, and
#  - internal:  the Datalift private data storage.
# All other names are available for module-specific repositories.
#
datalift.rdf.repositories       = data, internal
#
data.repository.default         = true
#
# Sesame HTTP repositories
#
data.repository.url             = \
        http://localhost:${datalift.port}/openrdf-sesame/repositories/lifted
#data.repository.username        = 
#data.repository.password        = 
#
internal.repository.url         = \
        http://localhost:${datalift.port}/openrdf-sesame/repositories/internal
#internal.repository.username    = 
#internal.repository.password    = 
#
#myrdfstore.repository.url        = \
#        http://localhost:${datalift.port}/openrdf-sesame/repositories/mystore
#myrdfstore.repository.label      = My RDF Store
#
# ============================================================================
#
# SPARQL endpoint configuration
#
# The maximum duration of a SPARQL query, as a number of seconds.
# Any query taking longer to execute than this configured threshold
# will be aborted and partial results returned to the user.
# Defaults to -1 (no time limit).
#
#sparql.max.query.duration       = 30
#
# The predefined SPARQL queries definition file
# This RDF file (Turtle, N3, RDF/XML...) defines the predefined queries to
# make available on the SPARQL endpoint HTML user interface. Each query
# shall have <http://www.datalift.org/core#SparqlQuery> as RDF type, zero
# to N labels (<http://www.w3.org/2000/01/rdf-schema#label>) and the query
# string as RDF value (<http://www.w3.org/1999/02/22-rdf-syntax-ns#value>).
#
sparql.predefined.queries.file  = ${datalift.home}/conf/predefined-queries.ttl
#
# Whether to use the Concise Bounded Description
# (http://www.w3.org/Submission/CBD/) feature provided by the back-end
# RDF store, to build RDF resource descriptions.
# Defaults to false, i.e. Datalift uses its own DESCRIBE query to include
# related blank nodes
#
#sparql.use.repository.cdb       = true
#
# Whether to include inferred triples when evaluating SPARQL queries.
# Defaults to true.
#
#sparql.include.inferred.triples = true
#
# The maximum number of results (triples, SPARQL results...) to
# return when outputting to HTML.
# Defaults to 1000.
#
#sparql.max.html.results         = 1000
#
# Whether named graphs shall be served in priority to resources in case
# the same URI exists describing both.
# Defaults to false.
#
#sparql.serve.graphs.first       = false
#
# ============================================================================
#
# Configuration of web access to RDF resources
#
# Whether to serve RDF resources before checking for files in public storage
# when resolving URIs.
# Defaults to false, i.e. files are checked and served first.
#
#datalift.resources.rdf.first    = false
#
# The duration (in seconds) the client is allowed to keep a representation in
# its local cache when a resource is accessed during business opening hours.
# Defaults to 2 hours (7200 seconds).
#
#datalift.cache.duration         = 7200
#
# The business opening hours. If a resource is accessed outside this range,
# the representation expiry date is the start of the next business day.
# The business day can cross the day boundary (e.g. 22:00-06:00) in case
# updates are being performed by nightly batches.
# Defaults to: 08:00-18:00
#
#datalift.cache.businessDay      = 08:00-18:00
#
# ============================================================================
#
# Project manager configuration
#
# The license definition file
# This RDF file (Turtle, N3, RDF/XML...) defines the supported licenses for
# projects. Each definition shall have <http://www.datalift.org/core#License>
# as RDF type, a license URI (<http://purl.org/dc/terms/license>) and zero
# to N labels (<http://www.w3.org/2000/01/rdf-schema#label>).
#
project.licenses.file           = ${datalift.home}/conf/licenses.ttl
#
# Batch size for RDF bulk operations
# Defaults to 10000.
#
datalift.rdf.batch.size         = 5000
#
# ============================================================================
#
